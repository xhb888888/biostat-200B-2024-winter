---
title: "hw2"
author: "Hanbei Xiong"
format: html
editor: visual
---

# Problem 1

![](images/WeChat065c203038c7e29ee155cea4a3a9dfe8.png)

**Answer:**

$SSR=\sum(\hat{Y}-\bar{Y})^2$

Since $(\bar{X},\bar{Y})$ must be on the estimated regression line.

$SSR=\sum(\hat{\beta_0}+\hat{\beta_1}X_i-\hat{\beta_0}-\hat{\beta_1}\bar{X})$

$SSR=\hat{\beta_1^2}\sum(X_i-\bar{X})^2$

$F=\frac{MSR}{MSE}=\frac{\frac{SSR}{1}}{\frac{SSE}{n-2}}=\frac{\hat{\beta_1^2}\sum(X_i-\bar{X})^2}{MSE}$

$SE(\hat{\beta_1})=\frac{\sqrt{MSE}}{\sqrt{\sum(X_i-\bar{X})^2}}$

Hence:

$F=\frac{\hat{\beta_1^2}}{SE(\hat{\beta_1})^2}=(\frac{\hat{\beta_1}}{SE(\hat{\beta_1})})^2=t^2$

# Problem 2

![](images/WeChatcbdaa452ae5d71d7c3dbd5b3de1dbe83.png)

Note:

$\hat{\beta_0}=\bar{Y}-\hat{\beta_1}\bar{X}$

$\hat{\beta_1}=\frac{\sum(X_i-\bar{X})(Y_i-\bar{Y})}{\sum(X_i-\bar{X})^2}$

$\hat{\sigma}^2=\frac{1}{n-2}\sum(Y_i-\bar{Y_i})^2$

$R^2=\frac{SSR}{SSTO}=\frac{\sum(\hat{Y_i}-\bar{Y})^2}{\sum(Y_i-\bar{Y})^2}$

$t=\frac{\hat{\beta_1}}{SE(\hat{\beta_1})}=\frac{\hat{\beta_1}\sqrt{\sum(X_i-\bar{X})^2}}{\hat{\sigma}}$

**(a) Answer:**

Given $x_i$ is replaced be $cx_i$,

$\hat{\beta_0^*}=\bar{Y}-\hat{\beta_1^*}(c\bar{X})=\hat{\beta_0}$

$\hat{\beta_1^*}=\frac{\sum(cX_i-c\bar{X})(Y_i-\bar{Y})}{\sum(cX_i-c\bar{X})^2}=\frac{c\sum(X_i-\bar{X})(Y_i-\bar{Y})}{c^2\sum(X_i-\bar{X})^2}=\frac{\sum(X_i-\bar{X})(Y_i-\bar{Y})}{c\sum(X_i-\bar{X})^2}=\frac{1}{c}\hat{\beta_1}$

$\hat{\sigma^*}^2=\frac{1}{n-2}\sum(Y_i-\bar{Y_i})^2=\hat{\sigma}^2$

$R^{*2}=\frac{\sum(\hat{Y_i^*}-\bar{Y})^2}{\sum(Y_i-\bar{Y})^2}=\frac{\sum(\hat{\beta_0^*}+\hat{\beta_1^*}cX_i-\bar{Y})^2}{\sum(Y_i-\bar{Y})^2}=\frac{\sum(\hat{\beta_0}+\frac{1}{c}\hat{\beta_1}cX_i-\bar{Y})^2}{\sum(Y_i-\bar{Y})^2}=R^{2}$

$t^*=\frac{\hat{\beta_1^*}\sqrt{\sum(cX_i-c\bar{X})^2}}{\hat{\sigma^*}}=\frac{\frac{1}{c}\hat{\beta_1}\sqrt{c^2\sum(X_i-\bar{X})^2}}{\hat{\sigma}}=\frac{\hat{\beta_1}\sqrt{\sum(X_i-\bar{X})^2}}{\hat{\sigma}}=t$

In this linear transformation, the $\hat{\beta_0}$, $\hat{\sigma}^2$, $t$-statistic and $R^2$ are invariant. The $\hat{\beta_1}$ is scaled by $\frac{1}{c}$.

**(b) Answer:**

Given $x_i$ is replaced be $x_i+d$,

$\hat{\beta_0^*}=\bar{Y}-\hat{\beta_1^*}(\bar{X}+d)=\bar{Y}-\hat{\beta_1}(\bar{X}+d)=\bar{Y}-\hat{\beta_1}\bar{X}-\hat{\beta_1}d=\hat{\beta_0}-\hat{\beta_1}d$

$\hat{\beta_1^*}=\frac{\sum((X_i+d)-(\bar{X}+d))(Y_i-\bar{Y})}{\sum((X_i+d)-(\bar{X}+d))^2}=\frac{\sum(X_i-\bar{X})(Y_i-\bar{Y})}{\sum(X_i-\bar{X})^2}=\hat{\beta_1}$

$\hat{\sigma^*}^2=\frac{1}{n-2}\sum(Y_i-\bar{Y_i})^2=\hat{\sigma}^2$

$R^{*2}=\frac{\sum(\hat{Y_i^*}-\bar{Y})^2}{\sum(Y_i-\bar{Y})^2}=\frac{\sum(\hat{\beta_0^*}+\hat{\beta_1^*}(X_i+d)-\bar{Y})^2}{\sum(Y_i-\bar{Y})^2}=\frac{\sum(\hat{\beta_0^*}+\hat{\beta_1^*}X_i+\hat{\beta_1^*}d-\bar{Y})^2}{\sum(Y_i-\bar{Y})^2}=\frac{\sum(\hat{\beta_0}-\hat{\beta_1}d+\hat{\beta_1}X_i+\hat{\beta_1}d-\bar{Y})^2}{\sum(Y_i-\bar{Y})^2}=R^{2}$

$t^*=\frac{\hat{\beta_1^*}\sqrt{\sum((X_i+d)-(\bar{X}+d))^2}}{\hat{\sigma^*}}=\frac{\hat{\beta_1}\sqrt{\sum(X_i-\bar{X})^2}}{\hat{\sigma}}=t$

In this linear transformation, the $\hat{\beta_1}$, $\hat{\sigma}^2$, $t$-statistic and $R^2$ are invariant. The $\hat{\beta_0}$ is shifted by $-\hat{\beta_1}d$.

**(c) Answer:**

Given $y_i$ is replaced be $ky_i$,

$\hat{\beta_0^*}=k\bar{Y}-\hat{\beta_1^*}\bar{X}=k\bar{Y}-k\hat{\beta_1}\bar{X}=k(\bar{Y}-\hat{\beta_1}\bar{X})=k\hat{\beta_0}$

$\hat{\beta_1^*}=\frac{\sum(X_i-\bar{X})(kY_i-k\bar{Y})}{\sum(X_i-\bar{X})^2}=\frac{k\sum(X_i-\bar{X})(Y_i-\bar{Y})}{\sum(X_i-\bar{X})^2}=k\hat{\beta_1}$

$\hat{\sigma^*}^2=\frac{1}{n-2}\sum(kY_i-k\bar{Y_i})^2=\frac{k^2}{n-2}\sum(Y_i-\bar{Y_i})^2=k^2\hat{\sigma}^2$

$R^{*2}=\frac{\sum(\hat{Y_i^*}-k\bar{Y})^2}{\sum(kY_i-k\bar{Y})^2}=\frac{\sum(\hat{\beta_0^*}+\hat{\beta_1^*}X_i-k\bar{Y})^2}{\sum(kY_i-k\bar{Y})^2}=\frac{\sum(k\hat{\beta_0}+k\hat{\beta_1}X_i-k\bar{Y})^2}{\sum(kY_i-k\bar{Y})^2}=\frac{k^2\sum(\hat{\beta_0}+\hat{\beta_1}X_i-\bar{Y})^2}{k^2\sum(Y_i-\bar{Y})^2}=R^2$

$t^*=\frac{\hat{\beta_1^*}\sqrt{\sum(X_i-\bar{X})^2}}{\hat{\sigma^*}}=\frac{k\hat{\beta_1}\sqrt{\sum(X_i-\bar{X})^2}}{k\hat{\sigma}}=\frac{\hat{\beta_1}\sqrt{\sum(X_i-\bar{X})^2}}{\hat{\sigma}}=t$

In this linear transformation, $\hat{\beta_0}$ and $\hat{\beta_1}$ are both scaled by k, $\hat{\sigma}^2$ is scaled by $k^2$, $t$-statistic and $R^2$ are invariant.

**(d) Answer:**

Given $y_i$ is replaced be $y_i+d$,

$\hat{\beta_0^*}=\bar{Y}+d-\hat{\beta_1^*}\bar{X}=\bar{Y}+d-\hat{\beta_1}\bar{X}=\hat{\beta_0}+d$

$\hat{\beta_1^*}=\frac{\sum(X_i-\bar{X})(Y_i+d-\bar{Y}-d)}{\sum(X_i-\bar{X})^2}=\frac{\sum(X_i-\bar{X})(Y_i-\bar{Y})}{\sum(X_i-\bar{X})^2}=\hat{\beta_1}$

$\hat{\sigma^*}^2=\frac{1}{n-2}\sum(Y_i+d-\bar{Y_i}-d)^2=\frac{1}{n-2}\sum(Y_i-\bar{Y_i})^2=\hat{\sigma}^2$

$R^{*2}=\frac{\sum(\hat{Y_i^*}-\bar{Y}-d)^2}{\sum(Y_i+d-\bar{Y_i}-d)^2}=\frac{\sum(\hat{\beta_0^*}+\hat{\beta_1^*}X_i-\bar{Y}-d)^2}{\sum(Y_i-\bar{Y})^2}=\frac{\sum(\hat{\beta_0}+d+\hat{\beta_1}X_i-\bar{Y}-d)^2}{\sum(Y_i-\bar{Y})^2}=\frac{\sum(\hat{Y_i}-\bar{Y})^2}{\sum(Y_i-\bar{Y})^2}=R^2$

$t^*=\frac{\hat{\beta_1^*}\sqrt{\sum(Y_i+d-\bar{Y_i}-d)^2}}{\hat{\sigma^*}}=\frac{\hat{\beta_1}\sqrt{\sum(Y_i-\bar{Y})^2}}{\hat{\sigma}}=t$

In this linear transformation, $\hat{\beta_0}$ is shifted by $d$, $\hat{\beta_1}$, $\hat{\sigma}^2$, $t$-statistic and $R^2$ are invariant.

**(e) Answer:**

I will list the associated quantities below in order ($\hat{\beta_0},\hat{\beta_1},\hat{\sigma}^2,R^2,t$)

Original scaling of variables: 75.92256, 0.53609, 19.372, 0.858, 20.42

a\) Convert age in month to age in year: 75.92256, 6.43307, 19.372, 0.858, 20.42

b\) Subtract mean age: 104.61972, 0.53609, 19.372, 0.858, 20.42

c\) Convert height in cm to height in inches: 29.89077, 0.21106, 3.0027, 0.858, 20.42

d\) Subtract mean height: -28.69716, 0.53609, 19.372, 0.858, 20.42

Each quantities after fitting model with transformation matches with my mathematical derivation in part a), b), c), d).

# Problem 3

![](images/WeChat3952ce67e4ef94d72d2391a272c0f795.png)

**Answer:**

Here are summary statistics generated in SAS:

![](images/WeChat8cc1a41f917226fdddeb69b1895ae3e2.png)

Here are histograms for each variable:

![](images/WeChata060745e77f93ba583534952e1ed98a0.png){width="255"}

![](images/WeChat966fd712658a8b6af1b7e0539fcbba9b.png){width="254"}

![](images/WeChata3a013e2681e45fa2a720717917489b7.png){width="256"}

![](images/WeChatcb3bf0ca858e00d9ee1fba142b726e92.png){width="259"}

By observing the summary statistics, the mean and median of each variable except "nurses" are close to each other, which indicates that the distribution of each variable is close to normal distribution. For variable "nurses", the mean is greater than the median which means there are right skewness in the distribution. By observing the histograms, the distribution of each variable except "nurses" is close to normal distribution. The distribution of "nurses" is right skewed. The histograms verify our interpretation of summary statistics.

## Here is scatter plot and fitted loess curves with different parameters for a) between Risk and nurses:

![](images/WeChatfe26f1121138843e86f434356706617e.png){width="378"}

We set parameter to be 0.6 and here is the plot we used to examine residuals:

![](images/WeChat62882ad9688733f5cd57f5bd5368edb9.png){width="340"}

Here is the original residuals analysis to check the assumptions:

![](images/WeChatdd94068e2a3eb5741699a0c376669d17.png){width="339"}

We can see residuals are more spread on left and more narrow to the right. Therefore, the constancy of error does not seem to meet. The linearity assumption is closely to meet. Residuals seem to distribute normally.

Since the loess curve is not showing a linear relationship between variables, we apply squared root transformation on x. Here is the updated scatter plot with fitted loess curve and residual analysis:

![](images/WeChat1f9b045994d50ef60cc89e5a96dfe9c7.png){width="347"}

![](images/WeChatc774a850fb00fbb1941d563708d61b9c.png){width="342"}

The plot after transformation still shows a non-linear relationship. Since we observe there is decreasing pattern at the end of original plot (before transformation), linear transformation might not be appropriate since data is not following a monotone pattern. However, it could also due to the fact that there are not enough data being collected on the right. Regarding the assumptions, the constancy of error seems to be verified after transformation. The linearity exist in the overall pattern. The distribution of residuals show normal pattern roughly.

## Here is scatter plot and fitted loess curves with different parameters for b) between Risk and length:

![](images/WeChat8eb6530ecc52d45c6025c9738b28e347.png){width="425"}

We set parameter to be 0.6 and here is the plot we used to examine residuals:

![](images/WeChatefcd1b33ccdb3c312a31737c42e115f2.png){width="361"}

Here is the original residuals analysis to check the assumptions:

![](images/WeChat2053fc89b8a1e6d1195b87d4d779645e.png){width="368"}

The constancy of error seems to meet as we ignore the outlier. The linearity assumption is closely to meet. Residuals seem to distribute normally. If we remove the outliers as we observe in the scatter plot, it should show a linear regression relationship. Therefore, we do not need to transform variables.

## Here is scatter plot and fitted loess curves with different parameters for c) between nurses and svcs:

![](images/WeChat5b8ca94d16adfa15b23155e7fa283104.png){width="384"}

We set parameter to be 0.6 and here is the plot we used to examine residuals:

![](images/WeChata913a4602c2d050ca512163ed0d43a1f.png){width="377"}

Here is the original residuals analysis to check the assumptions:

![](images/WeChat098aef49c4421e20448928be065a873b.png){width="374"}

The assumption of constant error is obviously violated. The linearity assumption is closely to meet. Residuals show normal distribution. Since the fitted loess curve is not showing an obvious linear relationship between variables. We apply log transformation on y. Here is the updated scatter plot with fitted loess curve and residual analysis:

![](images/WeChat12635750ae50342719996ee64b11229b.png){width="385"}

![](images/WeChatf026286a8104e363ccd30a4d567fefcf.png){width="379"}

Variables show a linear relationship after log transformation on nurses. Regarding assumptions, all assumptions seem to meet after this transformation.

# Problem 4

![](images/WeChatb2e8b640c9aea08a816ff2005aacd55c.png)

**(a) Answer:**

$\frac{\sum(X_i-\bar{X})(Y_i-\bar{Y})}{\sum(X_i-\bar{X})^2}=\frac{\sum(X_iY_i-X_i\bar{Y}-\bar{X}Y_i+\bar{X}\bar{Y})}{\sum(X_i-\bar{X})^2}$

$\frac{\sum(X_i-\bar{X})(Y_i-\bar{Y})}{\sum(X_i-\bar{X})^2}=\frac{\sum(X_iY_i-X_i\bar{Y}-\bar{X}Y_i)+n\frac{\sum{X_i}}{n}\bar{Y}}{\sum(X_i-\bar{X})^2}$

$\frac{\sum(X_i-\bar{X})(Y_i-\bar{Y})}{\sum(X_i-\bar{X})^2}=\frac{\sum(X_iY_i-X_i\bar{Y}-\bar{X}Y_i+X_i\bar{Y})}{\sum(X_i-\bar{X})^2}$

$\frac{\sum(X_i-\bar{X})(Y_i-\bar{Y})}{\sum(X_i-\bar{X})^2}=\frac{\sum(X_iY_i-\bar{X}Y_i)}{\sum(X_i-\bar{X})^2}$

$\frac{\sum(X_i-\bar{X})(Y_i-\bar{Y})}{\sum(X_i-\bar{X})^2}=\frac{\sum(X_i-\bar{X})Y_i}{\sum(X_i-\bar{X})^2}$

**(b) Answer:**

Let $c_i=\frac{X_i-\bar{X}}{\sum_{j=1}^{n}(X_j-\bar{X})^2}$

$Cov(\bar{Y},\hat{\beta_1})=Cov(\frac{1}{n}\sum{Y_i},\sum{c_iY_i})=\frac{1}{n}Cov(\sum{Y_i},\sum{c_iY_i})=\frac{1}{n}Cov(Y_1+Y_2+\dots+Y_n,c_1Y_1+c_2Y_2+\dots+c_nY_n)$

Since $Y_i$ are independent, $Cov(Y_i,Y_j)=0$ for $i\neq j$

$Cov(\bar{Y},\hat{\beta_1})=\frac{1}{n}(Cov(Y_1,c_1Y_1)+Cov(Y_2,c_2Y_2)+\dots+Cov(Y_n,c_nY_n))=\frac{1}{n}(\sum{c_iVar(Y_i)})=\frac{\sigma^2}{n}\sum{c_i}$

Since $\sum{c_i}=\frac{\sum(X_i-\bar{X})}{\sum_{j=1}^{n}(X_j-\bar{X})^2}=0$

$Cov(\bar{Y},\hat{\beta_1})=0$
